{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Training on full dataset\n",
    "12th Apr\n",
    "\n",
    "Same script as 11th Apr but I fixed bugs in logging after refact    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit job with only y<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2021.09.4 jupyter extensions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted quick_trainging jobs for /rds-d2/user/wjm41/hpc-work/models/dock2hit/D4/quick_train_ultra_negative on /rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets/ultra_large/D4_negative.pkl\n",
      "Submitted batch job 58770898\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dock2hit.utils import write_slurm_script\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets'\n",
    "log_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/runs/ultra-large/D4-debug'\n",
    "\n",
    "dataset = 'D4'\n",
    "model_name = 'quick_train_ultra_negative'\n",
    "model_dir = f'/rds-d2/user/wjm41/hpc-work/models/dock2hit/{dataset}'\n",
    "\n",
    "model_path = f'{model_dir}/{model_name}'\n",
    "\n",
    "data_path = f'{data_dir}/ultra_large/{dataset}_negative.pkl'\n",
    "\n",
    "script = f'python -c \"from dock2hit.train_and_validate.multithread import main; main()\"'\n",
    "\n",
    "log_step = 1\n",
    "args = [\n",
    "    f'-path_to_train_data {data_path}',\n",
    "    '-batch_size 256',\n",
    "    '-minibatch_size 64',\n",
    "    '-optimizer Adam',\n",
    "    '-lr 1e-1',\n",
    "    '-n_epochs 10000',\n",
    "    f'-save_dir {model_path}',\n",
    "    f'-log_dir {log_dir}',\n",
    "    f'-steps_per_log {log_step}'\n",
    "]\n",
    "\n",
    "file_name = 'subm_quick_train_ultra_negative'\n",
    "run_time = '0:05:00'\n",
    "output_name = f'{current_dir}/{file_name}.out'\n",
    "\n",
    "write_slurm_script(job_name=f'{file_name}',\n",
    "                   run_time=f'{run_time}',\n",
    "                   output_name=output_name,\n",
    "                   package_dir='/rds-d2/user/wjm41/hpc-work/datasets/Ugis/',\n",
    "                   script=script,\n",
    "                   args=args,\n",
    "                   file_name=file_name,\n",
    "                   email=True\n",
    "                   )\n",
    "\n",
    "print(f\"Submitted quick_trainging jobs for {model_path} on {data_path}\")\n",
    "\n",
    "!sbatch {file_name}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiny dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted quick_trainging jobs for /rds-d2/user/wjm41/hpc-work/models/dock2hit/D4/quick_train_ultra_tiny on /rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets/ultra_large/D4_test.csv\n",
      "Submitted batch job 58769953\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dock2hit.utils import write_slurm_script\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets'\n",
    "log_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/runs/ultra-large/D4-debug'\n",
    "\n",
    "dataset = 'D4'\n",
    "model_name = 'quick_train_ultra_tiny'\n",
    "model_dir = f'/rds-d2/user/wjm41/hpc-work/models/dock2hit/{dataset}'\n",
    "\n",
    "model_path = f'{model_dir}/{model_name}'\n",
    "\n",
    "data_path = f'{data_dir}/ultra_large/{dataset}_test.csv'\n",
    "\n",
    "script = f'python -c \"from dock2hit.train_and_validate.multithread import main; main()\"'\n",
    "\n",
    "log_step = 1\n",
    "args = [\n",
    "    f'-path_to_train_data {data_path}',\n",
    "    '-batch_size 256',\n",
    "    '-minibatch_size 64',\n",
    "    '-optimizer Adam',\n",
    "    '-lr 1e-1',\n",
    "    '-n_epochs 10000',\n",
    "    f'-save_dir {model_path}',\n",
    "    f'-log_dir {log_dir}',\n",
    "    f'-steps_per_log {log_step}'\n",
    "]\n",
    "\n",
    "file_name = 'subm_quick_train_ultra_tiny'\n",
    "run_time = '0:5:00'\n",
    "output_name = f'{current_dir}/{file_name}.out'\n",
    "\n",
    "write_slurm_script(job_name=f'{file_name}',\n",
    "                   run_time=f'{run_time}',\n",
    "                   output_name=output_name,\n",
    "                   package_dir='/rds-d2/user/wjm41/hpc-work/datasets/Ugis/',\n",
    "                   script=script,\n",
    "                   args=args,\n",
    "                   file_name=file_name,\n",
    "                   email=True\n",
    "                   )\n",
    "\n",
    "print(f\"Submitted quick_trainging jobs for {model_path} on {data_path}\")\n",
    "\n",
    "!sbatch {file_name}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted quick_trainging jobs for /rds-d2/user/wjm41/hpc-work/models/dock2hit/D4/quick_train_ultra_bigger on /rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets/ultra_large/D4_bigger_test.csv\n",
      "Submitted batch job 58776455\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dock2hit.utils import write_slurm_script\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets'\n",
    "log_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/runs/ultra-large/D4-debug'\n",
    "\n",
    "dataset = 'D4'\n",
    "model_name = 'quick_train_ultra_bigger'\n",
    "model_dir = f'/rds-d2/user/wjm41/hpc-work/models/dock2hit/{dataset}'\n",
    "\n",
    "model_path = f'{model_dir}/{model_name}'\n",
    "\n",
    "data_path = f'{data_dir}/ultra_large/{dataset}_bigger_test.csv'\n",
    "\n",
    "script = f'python -c \"from dock2hit.train_and_validate.multithread import main; main()\"'\n",
    "\n",
    "log_step = 50\n",
    "args = [\n",
    "    f'-path_to_train_data {data_path}',\n",
    "    '-batch_size 1024',\n",
    "    '-minibatch_size 64',\n",
    "    '-optimizer Adam',\n",
    "    '-lr 1e-3',\n",
    "    '-n_epochs 10000',\n",
    "    f'-save_dir {model_path}',\n",
    "    f'-log_dir {log_dir}',\n",
    "    f'-steps_per_log {log_step}'\n",
    "]\n",
    "\n",
    "file_name = f'subm_{model_name}'\n",
    "run_time = '0:20:00'\n",
    "output_name = f'{current_dir}/{file_name}.out'\n",
    "\n",
    "write_slurm_script(job_name=f'{file_name}',\n",
    "                   run_time=f'{run_time}',\n",
    "                   output_name=output_name,\n",
    "                   package_dir='/rds-d2/user/wjm41/hpc-work/datasets/Ugis/',\n",
    "                   script=script,\n",
    "                   args=args,\n",
    "                   file_name=file_name,\n",
    "                   email=True\n",
    "                   )\n",
    "\n",
    "print(f\"Submitted quick_trainging jobs for {model_path} on {data_path}\")\n",
    "\n",
    "!sbatch {file_name}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit leaky NN job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted quick_trainging jobs for /rds-d2/user/wjm41/hpc-work/models/dock2hit/D4/quick_train_ultra_bigger_leaky on /rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets/ultra_large/D4_bigger_test.csv\n",
      "Submitted batch job 58774266\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dock2hit.utils import write_slurm_script\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/datasets'\n",
    "log_dir = '/rds-d2/user/wjm41/hpc-work/datasets/Ugis/runs/ultra-large/D4-debug'\n",
    "\n",
    "dataset = 'D4'\n",
    "model_name = 'quick_train_ultra_bigger_leaky'\n",
    "model_dir = f'/rds-d2/user/wjm41/hpc-work/models/dock2hit/{dataset}'\n",
    "\n",
    "model_path = f'{model_dir}/{model_name}'\n",
    "\n",
    "data_path = f'{data_dir}/ultra_large/{dataset}_bigger_test.csv'\n",
    "\n",
    "script = f'python -c \"from dock2hit.train_and_validate.leaky_multithread import main; main()\"'\n",
    "\n",
    "log_step = 1\n",
    "args = [\n",
    "    f'-path_to_train_data {data_path}',\n",
    "    '-batch_size 256',\n",
    "    '-minibatch_size 64',\n",
    "    '-optimizer Adam',\n",
    "    '-lr 1e-3',\n",
    "    '-n_epochs 10000',\n",
    "    f'-save_dir {model_path}',\n",
    "    f'-log_dir {log_dir}',\n",
    "    f'-steps_per_log {log_step}'\n",
    "]\n",
    "\n",
    "file_name = f'subm_{model_name}'\n",
    "run_time = '0:5:00'\n",
    "output_name = f'{current_dir}/{file_name}.out'\n",
    "\n",
    "write_slurm_script(job_name=f'{file_name}',\n",
    "                   run_time=f'{run_time}',\n",
    "                   output_name=output_name,\n",
    "                   package_dir='/rds-d2/user/wjm41/hpc-work/datasets/Ugis/',\n",
    "                   script=script,\n",
    "                   args=args,\n",
    "                   file_name=file_name,\n",
    "                   email=True\n",
    "                   )\n",
    "\n",
    "print(f\"Submitted quick_trainging jobs for {model_path} on {data_path}\")\n",
    "\n",
    "!sbatch {file_name}\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6e87d9fa0a1f095b3ef96d553f4761a958bca4f905d671de5dacda23677a266"
  },
  "kernelspec": {
   "display_name": "fresco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
