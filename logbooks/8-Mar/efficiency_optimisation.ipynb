{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8th March 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created extra `train_and_validate` scripts to compare training speeds with:\n",
    "-  `collate` and `torch.utils.data.DataLoader`\n",
    "-  with parallelised feature generation using `pmap`\n",
    "-  with `pmap` and `concurrent.futures` multithread training\n",
    "\n",
    "by running speed testing script `python -m test/test_model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmed that training time per epoch with `collate` for `HIV.csv` was on par with that described in DGL-LifeSci arXiv paper (https://arxiv.org/pdf/2106.14232.pdf) - 2-3s per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimented with parallelised feature generation and dataloading for increased efficiency - found that using 4 cpus for both was optimal (50s total for 10 epochs vs 130s with only 1 process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to demonstrate speed increase with multithreading but `HIV.csv` is too small for direct comparison with `pmap` - I should compare against the original lazy implementation instead (make minibatch loop infinitely?)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6e87d9fa0a1f095b3ef96d553f4761a958bca4f905d671de5dacda23677a266"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dgl_cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
